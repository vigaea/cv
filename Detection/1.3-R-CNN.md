### 一、网络结构
1、Selective Search获取区域  
* 2000个区域建议
* 跟分类与关，包含物体    
  
2、区域预处理   
* 16像素(16p)的bounding box膨胀
* 尺寸变换成227x227   
  
3、AlexNet   
* 对输入的所有区域进行特征提取(FC7/1x4096)
* fine-tune   
  
4、分类(线性SVMs)   
* 对CNN特征(1x4096)进行分类
* 每个分类是一个2分类的SVM   

5、Bounding box回归   
* 每个分类是一个回归模型
* 基于CNN特征( conv5 )
* 精化SS的区域建议 
  
### 二、训练     
 虽然网络简单，但因其不是end-to-end的模型，训练较为复杂。严格来说模块间是独立的，像SS、CNN网络、SVM、bounding box回归   
1、pre-train   
在ImageNet上进行CNN模型的pre-train  

2、fine-tune  
微调为了更好地适应此数据集，使用所有的SS生成区域对pre-train model进行fine-tune  
* Loss: 概率loss值
* Softmax层由1000改为(N+1)way/21 or 201way/1为背景类  
* 32个正样本(N类)：与Ground truth IOU>=0.5   
* 96个负样本(1类)：IOU<0.5  

3、在fine-tune好模型的Fc7特征上训练线性SVMs分类器   
* Hinge loss   
* 每个类别(N类)对应一个SVM分类器
* 正样本：所有的Ground truth
* 负样本：与Ground truth重合IOU<0.3的SS区域 

4、在fine-tune好模型的conv5特征上训练bounding box回归模型   
![avator](http://pbbn8ldeq.bkt.clouddn.com/r-cnn.png)  

### 三、测试   
1、SS提取2000个区域建议

2、将SS的所有区域图片<font color=red>膨胀+缩放</font>到227x227    

3、使用fine-tune过的网络计算两套特征(Fc7+conv5)   
为每个类别分别执行以下操作(顺序执行):  
* Fc7特征-->SVM分类器-->类别分值(最高即为分类)
* 使用NMS( IOU>0.5)获取<font color=red>无冗余区域子集</font>   
   * 所有区域按分值降序排序  
   * 剔除与最大分值区域IOU>=0.5的所有区域
   * 保留最大分值区域，剩余区域为新候选集
* conv5特征->Bonding box回归模型-->get Bbox偏差
* 使用Bbox误差来修正区域子集   


### 四、不足   
1、重复计算   
CNN需要将每个图片的ROI都跑一遍，计算量太大而且重复性太高。   
2、训练复杂   
训练阶段多，而且训练时间长。在测试阶段也很慢

### PS:问题    
1、三个全连接层的作用？为什么使用fc7而不是fc8？  
首先卷积层是用来feature learning的，全连接层作用类似于分类器.   
选取fc7即倒数第二层的原因是，在保证原始特征的情况下最深层特征，而且最后一层fc与分类数量有关，带有很强的语义信息。(因为CNN的层数越深，提取的语义层级越高，特征提取的越充分)   
   
2、为什么使用线性SVM分类器？   
一方面SVM性能在论文中优于softmax，另一方面因为作者想验证CNN已经具有很强的特征学习提取能力，使用一个很简单的线性分类器就能达到很好的表现。

